{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pymssql\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = \"mssql-82792-0.cloudclusters.net:16272\"\n",
    "username = \"user\"\n",
    "password = \"RiceOwls1912\" \n",
    "database = \"ghz\"\n",
    "string = \"mssql+pymssql://\" + username + \":\" + password + \"@\" + server + \"/\" + database\n",
    "\n",
    "conn = create_engine(string).connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\n",
    "    \"\"\"\n",
    "    select date, ticker, acc, agr, beta, bm, ep, gma, idiovol,\n",
    "    lev, mom12m, mom1m, mve, operprof, roeq, ret\n",
    "    from data\n",
    "    order by date, ticker\n",
    "    \"\"\",\n",
    "    conn\n",
    "  )\n",
    "df = df.dropna()\n",
    "df = df.set_index([\"date\", \"ticker\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m transform \u001b[39m=\u001b[39m QuantileTransformer(output_distribution\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnormal\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mcolumns:\n\u001b[1;32m----> 3\u001b[0m     df[col] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mgroupby(\u001b[39m\"\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m\"\u001b[39;49m, group_keys\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[col]\u001b[39m.\u001b[39;49mtransform(transform)\n",
      "File \u001b[1;32mc:\\Users\\keb7\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:446\u001b[0m, in \u001b[0;36mSeriesGroupBy.transform\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[39m@Substitution\u001b[39m(klass\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSeries\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    444\u001b[0m \u001b[39m@Appender\u001b[39m(_transform_template)\n\u001b[0;32m    445\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, func, \u001b[39m*\u001b[39margs, engine\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, engine_kwargs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 446\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform(\n\u001b[0;32m    447\u001b[0m         func, \u001b[39m*\u001b[39margs, engine\u001b[39m=\u001b[39mengine, engine_kwargs\u001b[39m=\u001b[39mengine_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    448\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\keb7\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1834\u001b[0m, in \u001b[0;36mGroupBy._transform\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1831\u001b[0m func \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mget_cython_func(func) \u001b[39mor\u001b[39;00m func\n\u001b[0;32m   1833\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func, \u001b[39mstr\u001b[39m):\n\u001b[1;32m-> 1834\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform_general(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1836\u001b[0m \u001b[39melif\u001b[39;00m func \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m base\u001b[39m.\u001b[39mtransform_kernel_allowlist:\n\u001b[0;32m   1837\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is not a valid function name for transform(name)\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\keb7\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:470\u001b[0m, in \u001b[0;36mSeriesGroupBy._transform_general\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_transform_general\u001b[39m(\u001b[39mself\u001b[39m, func: Callable, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series:\n\u001b[0;32m    467\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m    Transform with a callable func`.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 470\u001b[0m     \u001b[39massert\u001b[39;00m callable(func)\n\u001b[0;32m    471\u001b[0m     klass \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m    473\u001b[0m     results \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "transform = QuantileTransformer(output_distribution=\"normal\")\n",
    "for col in df.columns:\n",
    "    df[col] = df.groupby(\"date\", group_keys=False)[col].transform(transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform1 = QuantileTransformer(\n",
    "    output_distribution=\"normal\"\n",
    ")\n",
    "\n",
    "transform2 = QuantileTransformer(\n",
    "    output_distribution=\"normal\"\n",
    ")\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "\n",
    "model = RandomForestRegressor(\n",
    "   random_state=0\n",
    ")\n",
    "\n",
    "pipe = make_pipeline(\n",
    "  poly,\n",
    "  model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "later = df.index.get_level_values(\"date\")>=\"2010-01\"\n",
    "\n",
    "train = df[~later]\n",
    "test = df[later]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\n",
    "  \"acc\", \"agr\", \"beta\", \"bm\", \"ep\", \"gma\", \"idiovol\",\n",
    "  \"lev\", \"mom12m\", \"mom1m\", \"mve\", \"operprof\", \"roeq\"\n",
    "]\n",
    "\n",
    "Xtrain = train[predictors]\n",
    "ytrain = train[\"ret\"]\n",
    "\n",
    "_ = pipe.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = test[predictors]\n",
    "\n",
    "ypredict = model.predict(Xtest)\n",
    "ypredict = pd.Series(ypredict, index=test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from modules.backtest import cumplot, mvplot, regress\n",
    "import datapane as dp\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load \n",
    "forest = load(\"forest2.joblib\")\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import pymssql\n",
    "import pandas as pd\n",
    "\n",
    "server = \"mssql-82792-0.cloudclusters.net:16272\"\n",
    "username = \"user\"\n",
    "password = \"RiceOwls1912\" # paste password between quote marks\n",
    "database = \"ghz\"\n",
    "\n",
    "string = \"mssql+pymssql://\" + username + \":\" + password + \"@\" + server + \"/\" + database\n",
    "\n",
    "conn = create_engine(string).connect()\n",
    "\n",
    "data = pd.read_sql(\n",
    "    \"\"\"\n",
    "    select ticker, date, ret, roeq, mom12m, siccd\n",
    "    from data\n",
    "    where date='2022-01'\n",
    "    \"\"\", \n",
    "    conn\n",
    ")\n",
    "data = data.dropna()\n",
    "\n",
    "X = data[[\"roeq\", \"mom12m\"]]\n",
    "data[\"predict\"] = forest.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(\n",
    "  by=\"predict\",\n",
    "  ascending=False\n",
    ")\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with create_engine(\"sqlite:///files/mydata.db\").connect() as conn:\n",
    "    rets = pd.read_sql(\"select * from model1\", conn)\n",
    "    rets[\"market\"] = pd.read_sql(\"select market from market\", conn)\n",
    "    rets[\"rf\"] = pd.read_sql(\"select rf from market\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "    The features are roeq and mom12m.  The feature pipeline is (QuantileTransformer, \n",
    "    PolynomialFeatures, QuantileTransformer).  The target is the return minus the\n",
    "    market return and ias transformed with QuantileTransformer.  Random forests with\n",
    "    max_depth=4 are trained at five-year intervals and used to predict monthly.  The best\n",
    "    and worst returns are the equally weighted returns of the top 100 and bottom 100 stocks\n",
    "    each month, respectively.\n",
    "\"\"\"\n",
    "\n",
    "figa = cumplot(rets)\n",
    "figb = mvplot(rets)\n",
    "tbla = regress(rets, \"best\")\n",
    "tblb = regress(rets, \"worst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kerry\\repos\\2022-638-binder\\venv\\lib\\site-packages\\datapane\\common\\df_processor.py:28: FutureWarning:\n",
      "\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "App saved to ./files/dashboard.html"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pg = dp.Page(\n",
    "    title=\"Random Forest\",\n",
    "    blocks = [\n",
    "        \"## Random Forest Model\",\n",
    "        \"Kerry Back, November 28, 2022\",\n",
    "        text,\n",
    "        dp.Select(\n",
    "            dp.Plot(\n",
    "                figa, \n",
    "                caption=\"Cumulative Returns\",\n",
    "                label=\"Cumulative returns\"\n",
    "            ),\n",
    "            dp.DataTable(\n",
    "                tbla, \n",
    "                caption=\"\"\"\n",
    "                    Regression of Best-RF on Mkt-RF.  The alpha estimate is\n",
    "                    in percent per year.\n",
    "                \"\"\",\n",
    "                label=\"Alpha and beta of best portfolio\"\n",
    "            ),\n",
    "            dp.DataTable(\n",
    "                tblb, \n",
    "                caption=\"\"\"\n",
    "                    Regression of Worst-RF on Mkt-RF.  The alpha estimate is\n",
    "                    in percent per year.\n",
    "                \"\"\",\n",
    "                label=\"Alpha and beta of worst portfolio\"\n",
    "            ),\n",
    "            dp.Plot(\n",
    "                figb, \n",
    "                caption=\"Mean-Variance Analysis\",\n",
    "                label=\"Mean-variance analysis\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "app = dp.App(\n",
    "    pg,\n",
    ")\n",
    "app.save(\"files/dashboard.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to create an html file with separate pages for different models, you can create each page as in the above and then use something like\n",
    "\n",
    "    app = dp.App(\n",
    "        pg1, \n",
    "        pg2,\n",
    "        pg3\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datapane.com will host your html file for free.  Just create an account, get your login token and add the following two lines to your notebook.  You will then get a link that you can share.\n",
    "\n",
    "    !datapane login --token=whateverYourTokenIs\n",
    "    app.upload(name=\"WhateverYouWantToCallIt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# \n",
    "# !datapane login --token=\n",
    "# app.upload(name=\"Investment Strategy Backtests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff49 = pd.read_excel(\"ff49.xlsx\", index_col=0)\n",
    "def industry(sic):\n",
    "  try:\n",
    "    return ff49[(ff49.lower<=sic)&(sic<=ff49.upper)].index[0]\n",
    "  except:\n",
    "    return \"Almost Nothing\"\n",
    "top[\"industry\"] = top.siccd.map(industry)\n",
    "counts = top.groupby(\"industry\").ticker.count()\n",
    "counts = counts.rename(index={\"Almost Nothing\": \"Other\"})\n",
    "counts = counts.reset_index()\n",
    "counts.columns = [\"industry\", \"count\"]\n",
    "\n",
    "import plotly.express as px\n",
    "fig = px.pie(counts, values=\"count\", names=\"industry\")\n",
    "\n",
    "fig.update_layout(\n",
    "    template=\"plotly_dark\",\n",
    "    font_size=20,\n",
    "    width=1000,\n",
    "    height=800,\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fde46c13439050da17ff960cfbfb27519ac693264eff9f61b85b21506eee5af7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
